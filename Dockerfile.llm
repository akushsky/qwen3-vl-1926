FROM nvidia/cuda:12.1.1-runtime-ubuntu22.04

# Install system dependencies
RUN apt-get update && apt-get install -y \
    python3 \
    python3-pip \
    git \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Install vLLM
RUN pip3 install vllm

# Set working directory
WORKDIR /app

# Expose port
EXPOSE 8000

# Run vLLM server with your specified parameters
CMD ["python3", "-m", "vllm.entrypoints.openai.api_server", \
     "--model", "Qwen/Qwen3-VL-8B-Instruct-FP8", \
     "--dtype", "auto", \
     "--trust-remote-code", \
     "--kv-cache-dtype", "fp8", \
     "--max-model-len", "2466", \
     "--max-num-batched-tokens", "512", \
     "--max-num-seqs", "1", \
     "--gpu-memory-utilization", "0.88", \
     "--swap-space", "6", \
     "--limit-mm-per-prompt.image", "1", \
     "--limit-mm-per-prompt.video", "0", \
     "--enforce-eager", \
     "--host", "0.0.0.0", \
     "--port", "8000"]
